{
    "collab_server" : "",
    "contents" : "setwd(\"~/Dropbox/Kaggle/Santander--20160502\")\n\ninstall.packages(\"ROCR\")\nlibrary(ROCR)\nlibrary(ggplot2)\n\ninstall.packages(\"randomForest\")\nlibrary(randomForest)\n\n#install.packages(\"h2o\")\nlibrary(h2o)\nlocalH2O = h2o.init(nthreads=-1)\n\n#Background\n#Target \"0\" means satisfied, \"1\" means dissatisfied\n\n\n\n##Kaggle Forum\n#https://www.kaggle.com/c/santander-customer-satisfaction/forums/t/19717/how-the-score-is-calculated/113133\n\n##Kaggle starter scripts##\n#https://www.kaggle.com/arjbuzz/santander-customer-satisfaction/starter-r-script-lb-0-840310/code\n#https://www.kaggle.com/hulkbulk/santander-customer-satisfaction/santander-starter\n# H2O https://www.kaggle.com/jofaichow/santander-customer-satisfaction/h2o-gbm-starter\n\n#h2o sites\n# https://github.com/h2oai/h2o-training-book/blob/master/hands-on_training/classification.md\n\n##Other userful sites\n#http://blog.yhat.com/posts/roc-curves.html\n\n\n\n##Thoughts\n#functions to scrub data: zeros, replicated columns (unique)\n#validate similarity of test data and missing data: merge data to avoid duplication?\n#set up h2o and run on stanford or AWS serversn\n\n#try MARS?\n\n#read data\ntrainData <- read.csv(file = \"train.csv\") #371 variables with 1 id and 1 target\ntestData <- read.csv(file = \"test.csv\")\nsubmitData <- read.csv(file = \"sample_submission.csv\")\n\n#convert TARGET to factor\n\ntrainData$TARGET <- as.factor(trainData$TARGET)\n\n#sampled data\n\n\n##simple randomForest\n\n#rf model\nset.seed(1)\n#sample <- trainData[sample(1:nrow(trainData), 25000, replace=FALSE),]\n\nset.seed(1)\n#data <- sample\ndata <- trainData\ntrain <- (sample(1:nrow(data), nrow(data)*.67))\nm <- as.integer(sqrt(length(data)))\ny_train <- data$TARGET[train]\nx_train <- data[,-which(names(data)==\"TARGET\")][train,]\ny_test <- data$TARGET[-train] #change to valid\nx_test <- data[,-which(names(data)==\"TARGET\")][-train,] #change to valid\n\n\n\nmodelRF <- randomForest(y = y_train, x = x_train, ytest = y_test, xtest = x_test, importance = TRUE, keep.forest = TRUE, mtry = m)\nmodelRF$confusion\n#head(modelRF)\nprobRF <- modelRF$test$votes[,2]\n\n#ROC and AUC\n#source: http://blog.yhat.com/posts/roc-curves.html\n\npredRF <- prediction(probRF, labels = y_test)\nperfRF <- performance(predRF, measure = \"tpr\", x.measure = \"fpr\")\n\nauc <- performance(predRF, measure = \"auc\")\nauc <- auc@y.values[[1]]\n\nroc.data <- data.frame(fpr=unlist(perfRF@x.values),\n  tpr=unlist(perfRF@y.values),\n  model=\"RF\")\nggplot(roc.data, aes(x=fpr, ymin=0, ymax=tpr)) +\n  geom_ribbon(alpha=0.2) +\n  geom_line(aes(y=tpr)) +\n  ggtitle(paste0(\"ROC Curve w/ AUC=\", auc))\n\n#reviewing results\n\n\n##using h2o random forest\n#read data\nsetwd(\"~/Dropbox/Kaggle/Santander--20160502\")\n\n#install.packages(\"h2o\")\nlibrary(h2o)\nlocalH2O = h2o.init(nthreads=-1)\n\ntrainData <- read.csv(file = \"train.csv\") #371 variables with 1 id and 1 target\ntestData <- read.csv(file = \"test.csv\")\nsubmitData <- read.csv(file = \"sample_submission.csv\")\ntrainData$TARGET <- as.factor(trainData$TARGET) #need to set response as a factor to classify\n\n#create sample\nset.seed(1)\nsample <- trainData[sample(1:nrow(trainData), 25000, replace=FALSE),]\n\n#create training set\nset.seed(1)\n#data <- sample\ndata <- trainData\ntrain <- (sample(1:nrow(data), nrow(data)*.67))\n\nh2oData <- as.h2o(data, destination_frame = \"h2oData\")\nylabel <- \"TARGET\"\nxlabel <- names(data[,-which(names(data)==\"TARGET\")])\nh2oTrain <- as.h2o(data[train,], destination_frame = \"h2oTrain\")\nh2oValid <- as.h2o(data[-train,], destination_frame = \"h2oTrain\")\n\n#model with sample and validation set\n\nh2oRF <- h2o.randomForest(x = xlabel,\n                           y = ylabel,\n                           training_frame = h2oTrain, #full dataset\n                           validation_frame = h2oValid,\n                           mtries = -1,\n                           binomial_double_trees = TRUE,\n                           seed = 1)\n\n#saveRDS(h2oRF, file = \"h2oMod.rds\")\n\n\n#rebuild model model from full dataset\n\nh2oFullRF <- h2o.randomForest(x = xlabel,\n                           y = ylabel,\n                           training_frame = h2oData,\n                           mtries = -1,\n                           binomial_double_trees = TRUE,\n                           seed = 1)\n\n#saveRDS(h2oMod, file = \"h2oMod.rds\")\n\n#prediction from test dataset\nh2oTest <- as.h2o(testData, destination_frame = \"h2oTest\")\npredict_h2oRF <- h2o.predict(h2oFullRF,h2oTest)\n\nrunSubmitRF <- submitData\nrunSubmit$TARGET <- as.vector(predict_h2oRF[,3])\n\n#save csv file with predictions\nwrite.csv(betaSubmit, file = \"beta_submission_20160414_2.csv\",row.names = FALSE)\n\n\n##----h20 GBM----##\n\n#training model\n\nh2oGBM <- h2o.gbm(x = xlabel,\n                          y = ylabel,\n                          training_frame = h2oTrain, #full dataset\n                          validation_frame = h2oValid,\n                          distribution = \"AUTO\")\n\n\nh2oGBM@model$validation_metrics@metrics$AUC\nh2o.confusionMatrix(h2oGBM)\n\n#no impact from stopping_metric = \"AUC\"\n\n#full model\nh2oFullGBM <- h2o.gbm(x = xlabel,\n                  y = ylabel,\n                  training_frame = h2oData, #full dataset\n                  distribution = \"AUTO\",\n                  seed = 1)\n\n\n\n#predict and write csv file\nh2oTest <- as.h2o(testData, destination_frame = \"h2oTest\")\npredict_h2oGBM <- h2o.predict(h2oFullGBM,h2oTest)\n\nrunSubmitGBM <- submitData\nrunSubmitGBM$TARGET <- as.vector(predict_h2oGBM[,3])\n\nwrite.csv(runSubmitGBM, file = \"S_submission_20160415_1.csv\",row.names = FALSE)\n\n#Grid search for model comparison\n#source: https://h2o-release.s3.amazonaws.com/h2o/rel-slater/9/docs-website/h2o-docs/booklets/GBM_Vignette.pdf\n\nntrees_opt <- list(5,10,15,50) #default is 50\nmaxdepth_opt <- list(2,3,4,5) #default is 5\nlearnrate_opt <- list(0.05,0.1,0.2) #default is 0.1\nhyper_parameters <- list(ntrees=ntrees_opt, max_depth=maxdepth_opt,\n                         learn_rate=learnrate_opt)\n\ngrid <- h2o.grid(\"gbm\", \n                 hyper_params = hyper_parameters,\n                 y = ylabel,\n                 x = xlabel,\n                 distribution=\"bernoulli\", \n                 training_frame = h2oTrain,\n                 validation_frame = h2oValid)\n\n# print out all prediction errors and run times of the models\ngrid\n\n# print out the auc for all of the models\ngrid_models <- lapply(grid@model_ids, function(model_id) {\n  model = h2o.getModel(model_id) })\nfor (i in 1:length(grid_models)) {\n  print(sprintf(\"auc: %f\", h2o.auc(grid_models[[i]])))\n  }\n",
    "created" : 1461359621285.000,
    "dirty" : false,
    "encoding" : "UTF-8",
    "folds" : "",
    "hash" : "2186671761",
    "id" : "6D782CF6",
    "lastKnownWriteTime" : 1461361997,
    "last_content_update" : 1461361997399,
    "path" : "~/Dropbox/Kaggle/Santander--20160502/santander_scratch1.R",
    "project_path" : null,
    "properties" : {
    },
    "relative_order" : 1,
    "source_on_save" : false,
    "source_window" : "",
    "type" : "r_source"
}